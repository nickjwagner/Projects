{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = pd.read_csv('/users/nick/desktop/sentences.csv')\n",
    "sentences.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If you haven't looked at the EDA file -- principal analysis will be on 2008 - 2012 data, with sentences limited\n",
    "# to 'new commitments,' looking only at the black and white inmate populations.  \n",
    "five = sentences.loc[(sentences.ADMITYR >= 2008) & (sentences.ADMITYR <= 2012) & (sentences.admtype_ == 'New commitment')].copy()\n",
    "five.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# As said in the EDA file: most states have some quantity of missing data, but it is particularly glaring w/r/t \n",
    "# Alabama's prison demographics. Research reveals that Alabama's 'Missing' population is a close match with \n",
    "# its known population of black inmates.\n",
    "for i, e in enumerate(five.race_):\n",
    "    if five.loc[i, 'state_'] == 'AL':\n",
    "        if e == 'Missing':\n",
    "            five.loc[i, 'race_'] = 'Black'\n",
    "            \n",
    "race = five.loc[(five.race_ == 'Black') | (five.race_ == 'White')].copy()\n",
    "race.dropna(subset=['proj_time_served'], how='any', inplace=True)\n",
    "race.race_ = race.race_.apply(lambda x: 1 if x == 'Black' else 0)\n",
    "race.reltype_ = race.reltype_.apply(lambda x: 1 if x == 'Conditional release' else 0)\n",
    "race.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "race.to_csv('/users/nick/desktop/race.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "race = pd.read_csv('/users/nick/desktop/race.csv')\n",
    "race.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When modeling on unbalanced data, it's important to 'stratify' -- to make sure that the actual distribution of classes (in this case, the black inmate population and the white inmate population) is maintained across the training and testing data. (If class proportion is different in training data than testing data, the model will suffer.) But I'd also like to make sure that states are properly represented in both training and testing data. Since some states issue far more sentences than others, dummy variables don't offer a perfect solution: there's still a chance that (e.g.) Delaware's data falls primarily in the testing set, and so its sentences are predicted by sentences in other states. And so rather than build one model for all states, I'm building one model for each state. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For modelling, I use an \"Extreme Gradient Boosting\" classifier ... like sklearn's GBM but better engineered (http://xgboost.readthedocs.io/en/latest/). Since I'm also optimizing each model, I use 'nested cross-validation' as protection against overfitting. See: http://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_estimators=200)\n",
    "inner_cv = StratifiedKFold(n_splits = 4, shuffle=True, random_state = 1)\n",
    "outer_cv = StratifiedKFold(n_splits = 4, shuffle=True, random_state = 2)\n",
    "p_grid = {'max_depth': [3,4,5],\n",
    "          'min_child_weight': [2, 5, 10]}\n",
    "\n",
    "def prediction_compiler(states):\n",
    "    \n",
    "    true = []\n",
    "    pred = []\n",
    "    sts = []   \n",
    "    \n",
    "    for state in states:\n",
    "        X = race.loc[race.state_ == state][['SEX', 'off_detail', 'age_admit', 'reltype_', 'proj_time_served']]\n",
    "        X.iloc[:,:-2] = X.iloc[:,:-2].apply(LabelEncoder().fit_transform)\n",
    "        y = race.loc[race.state_ == state].race_.values\n",
    "        \n",
    "        gs = GridSearchCV(estimator = xgb, param_grid = p_grid, cv = inner_cv)\n",
    "        y_pred = cross_val_predict(gs, X, y, cv= outer_cv)\n",
    "        \n",
    "        true.extend(y)   \n",
    "        pred.extend(y_pred)\n",
    "        st = [state] * len(y)\n",
    "        sts.extend(st)\n",
    "        \n",
    "    df = pd.DataFrame({ 'State': sts,\n",
    "                        'true': true, \n",
    "                        'pred': pred })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6745759412660004"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = race.state_.unique()\n",
    "\n",
    "model = prediction_compiler(states)\n",
    "model['match'] = model.pred + model.true\n",
    "model.match = model.match.apply(lambda x: 1 if x == 2 or x == 0 else 0)\n",
    "\n",
    "float(model.match.sum()) / len(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score to beat -- 'baseline' -- which you'd get by predicting that all inmates are white since they are the larger class, is 54.4%. \n",
    "\n",
    "It's worth mentioning that this process (building and optimizing 40+ models, which took ~5 hours to run, as opposed to building a single model, which only takes minutes) did not significantly improve predictive performance. A single model had 65.6% accuracy, while modeling for each state but skipping optimization had 66.5% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trends = pd.DataFrame((model.groupby('State').match.sum() / model.groupby('State').match.count()) * 100)\n",
    "\n",
    "trends['baseline'] = model.groupby('State').true.sum() / model.groupby('State').true.count()\n",
    "trends.baseline = trends.baseline.apply(lambda x: (1 - x) * 100 if x < 0.5 else x * 100)\n",
    "trends['difference'] = trends.match - trends.baseline\n",
    "trends.difference = trends.difference.apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "trends.reset_index(inplace=True)\n",
    "trends = trends.iloc[1:,:]\n",
    "trends.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>match</th>\n",
       "      <th>baseline</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>61.763455</td>\n",
       "      <td>51.415094</td>\n",
       "      <td>10.348361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZ</td>\n",
       "      <td>76.932320</td>\n",
       "      <td>76.711623</td>\n",
       "      <td>0.220696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>61.446365</td>\n",
       "      <td>53.512204</td>\n",
       "      <td>7.934161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CO</td>\n",
       "      <td>74.585799</td>\n",
       "      <td>73.988166</td>\n",
       "      <td>0.597633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DC</td>\n",
       "      <td>98.682064</td>\n",
       "      <td>98.682064</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DE</td>\n",
       "      <td>57.450319</td>\n",
       "      <td>52.363871</td>\n",
       "      <td>5.086448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FL</td>\n",
       "      <td>65.885397</td>\n",
       "      <td>52.465869</td>\n",
       "      <td>13.419528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GA</td>\n",
       "      <td>66.082741</td>\n",
       "      <td>62.984344</td>\n",
       "      <td>3.098397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IA</td>\n",
       "      <td>73.570552</td>\n",
       "      <td>72.924335</td>\n",
       "      <td>0.646217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IL</td>\n",
       "      <td>67.881094</td>\n",
       "      <td>64.085398</td>\n",
       "      <td>3.795696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IN</td>\n",
       "      <td>69.727789</td>\n",
       "      <td>68.709500</td>\n",
       "      <td>1.018289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KS</td>\n",
       "      <td>67.714256</td>\n",
       "      <td>66.142872</td>\n",
       "      <td>1.571384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KY</td>\n",
       "      <td>80.073543</td>\n",
       "      <td>79.978123</td>\n",
       "      <td>0.095420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MA</td>\n",
       "      <td>72.679470</td>\n",
       "      <td>64.677641</td>\n",
       "      <td>8.001829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ME</td>\n",
       "      <td>92.385581</td>\n",
       "      <td>92.426083</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MN</td>\n",
       "      <td>64.262275</td>\n",
       "      <td>60.725571</td>\n",
       "      <td>3.536704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MO</td>\n",
       "      <td>73.158633</td>\n",
       "      <td>71.062636</td>\n",
       "      <td>2.095997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MS</td>\n",
       "      <td>66.118232</td>\n",
       "      <td>63.081117</td>\n",
       "      <td>3.037115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NC</td>\n",
       "      <td>62.470420</td>\n",
       "      <td>56.444047</td>\n",
       "      <td>6.026373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ND</td>\n",
       "      <td>91.080278</td>\n",
       "      <td>91.179386</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NE</td>\n",
       "      <td>71.248528</td>\n",
       "      <td>70.082450</td>\n",
       "      <td>1.166078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NH</td>\n",
       "      <td>94.002999</td>\n",
       "      <td>94.002999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NJ</td>\n",
       "      <td>71.265459</td>\n",
       "      <td>68.165546</td>\n",
       "      <td>3.099913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NM</td>\n",
       "      <td>76.935419</td>\n",
       "      <td>77.015644</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NV</td>\n",
       "      <td>65.531619</td>\n",
       "      <td>62.638196</td>\n",
       "      <td>2.893423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NY</td>\n",
       "      <td>69.978518</td>\n",
       "      <td>61.600430</td>\n",
       "      <td>8.378088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OH</td>\n",
       "      <td>63.761395</td>\n",
       "      <td>56.728770</td>\n",
       "      <td>7.032624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>OK</td>\n",
       "      <td>67.362223</td>\n",
       "      <td>66.170513</td>\n",
       "      <td>1.191710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>OR</td>\n",
       "      <td>89.952706</td>\n",
       "      <td>90.005255</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PA</td>\n",
       "      <td>69.363187</td>\n",
       "      <td>50.373655</td>\n",
       "      <td>18.989532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RI</td>\n",
       "      <td>70.673145</td>\n",
       "      <td>68.948035</td>\n",
       "      <td>1.725109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SC</td>\n",
       "      <td>64.476445</td>\n",
       "      <td>61.182884</td>\n",
       "      <td>3.293561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SD</td>\n",
       "      <td>92.311266</td>\n",
       "      <td>92.334495</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TN</td>\n",
       "      <td>64.641760</td>\n",
       "      <td>56.734501</td>\n",
       "      <td>7.907259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>TX</td>\n",
       "      <td>61.027808</td>\n",
       "      <td>52.181252</td>\n",
       "      <td>8.846556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UT</td>\n",
       "      <td>91.545687</td>\n",
       "      <td>91.545687</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>WA</td>\n",
       "      <td>79.323423</td>\n",
       "      <td>79.391148</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>WI</td>\n",
       "      <td>67.650337</td>\n",
       "      <td>58.651936</td>\n",
       "      <td>8.998401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>WV</td>\n",
       "      <td>87.502736</td>\n",
       "      <td>87.531918</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>WY</td>\n",
       "      <td>94.726097</td>\n",
       "      <td>94.726097</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State      match   baseline  difference\n",
       "0     AL  61.763455  51.415094   10.348361\n",
       "1     AZ  76.932320  76.711623    0.220696\n",
       "2     CA  61.446365  53.512204    7.934161\n",
       "3     CO  74.585799  73.988166    0.597633\n",
       "4     DC  98.682064  98.682064    0.000000\n",
       "5     DE  57.450319  52.363871    5.086448\n",
       "6     FL  65.885397  52.465869   13.419528\n",
       "7     GA  66.082741  62.984344    3.098397\n",
       "8     IA  73.570552  72.924335    0.646217\n",
       "9     IL  67.881094  64.085398    3.795696\n",
       "10    IN  69.727789  68.709500    1.018289\n",
       "11    KS  67.714256  66.142872    1.571384\n",
       "12    KY  80.073543  79.978123    0.095420\n",
       "13    MA  72.679470  64.677641    8.001829\n",
       "14    ME  92.385581  92.426083    0.000000\n",
       "15    MN  64.262275  60.725571    3.536704\n",
       "16    MO  73.158633  71.062636    2.095997\n",
       "17    MS  66.118232  63.081117    3.037115\n",
       "18    NC  62.470420  56.444047    6.026373\n",
       "19    ND  91.080278  91.179386    0.000000\n",
       "20    NE  71.248528  70.082450    1.166078\n",
       "21    NH  94.002999  94.002999    0.000000\n",
       "22    NJ  71.265459  68.165546    3.099913\n",
       "23    NM  76.935419  77.015644    0.000000\n",
       "24    NV  65.531619  62.638196    2.893423\n",
       "25    NY  69.978518  61.600430    8.378088\n",
       "26    OH  63.761395  56.728770    7.032624\n",
       "27    OK  67.362223  66.170513    1.191710\n",
       "28    OR  89.952706  90.005255    0.000000\n",
       "29    PA  69.363187  50.373655   18.989532\n",
       "30    RI  70.673145  68.948035    1.725109\n",
       "31    SC  64.476445  61.182884    3.293561\n",
       "32    SD  92.311266  92.334495    0.000000\n",
       "33    TN  64.641760  56.734501    7.907259\n",
       "34    TX  61.027808  52.181252    8.846556\n",
       "35    UT  91.545687  91.545687    0.000000\n",
       "36    WA  79.323423  79.391148    0.000000\n",
       "37    WI  67.650337  58.651936    8.998401\n",
       "38    WV  87.502736  87.531918    0.000000\n",
       "39    WY  94.726097  94.726097    0.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trends.to_csv('/users/nick/desktop/trends.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
